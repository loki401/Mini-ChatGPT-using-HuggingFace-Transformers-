# Mini-ChatGPT-using-HuggingFace-Transformers-
Built a lightweight conversational AI assistant using the GPT2-small model from HuggingFace. Implemented a Flask-based web interface for real-time user interaction. Designed prompt templates to simulate human-AI dialogue and handled model inference using PyTorch. Applied sampling techniques (top-k, top-p, temperature) 

# ğŸ§  Mini ChatGPT using GPT-2

A lightweight chatbot powered by **GPT-2 small** and deployed with **Gradio**. This project simulates a basic conversational AI using HuggingFace Transformers.

> ğŸš€ Built and deployed by [Logesh Murugan](https://www.linkedin.com/in/logesh-m-72b801258/)

---

## ğŸŒ Live Demo

ğŸ‘‰ [Click here to try the chatbot live](https://huggingface.co/spaces/muruganlogesh/projects)

---

## ğŸ’¡ Features

- ğŸ¤– Chatbot built with GPT2-small
- ğŸ§  Real-time text generation
- ğŸª„ Prompt engineering for simple conversation flow
- ğŸŒ Deployed on Hugging Face Spaces using Gradio

---

## ğŸ“¦ Tech Stack

- Python
- Gradio
- Transformers (HuggingFace)
- PyTorch

---

## ğŸ› ï¸ How It Works

1. User types a message
2. The message is appended to a prompt format: `Human: <message>\nAI:`
3. The GPT-2 model generates a continuation
4. The response is shown in the Gradio interface

---

## ğŸ“ Files

- `app.py` â€” Core chatbot logic
- `requirements.txt` â€” Dependencies
- `README.md` â€” You're reading it!

---

## ğŸ§‘â€ğŸ’» Author

**Logesh Murugan**  
- ğŸ“ AI & Data Science Student, Panimalar Engineering College  
- ğŸ”— [LinkedIn](https://www.linkedin.com/in/logesh-m-72b801258/)  
- ğŸ’» [GitHub](https://github.com/lebazirmoses)

---

## ğŸ“ Notes

- GPT-2 is not fine-tuned; it's the raw pre-trained version.
- You can upgrade this by:
  - Fine-tuning on custom Q&A data
  - Switching to OpenAI GPT-3.5 via API
  - Adding memory / chat history
